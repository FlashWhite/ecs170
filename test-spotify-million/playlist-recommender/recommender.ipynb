{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch environment variables\n",
    "load_dotenv()\n",
    "CLIENT_ID = os.getenv('CLIENT_ID')\n",
    "CLIENT_SECRET = os.getenv('CLIENT_SECRET')\n",
    "\n",
    "# Set up Spotify API credentials\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=CLIENT_ID, client_secret=CLIENT_SECRET)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ GET USER PLAYLIST DATA ------------------------------\n",
    "features = ['danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
    "user_playlist = pd.read_csv('../Playlists/hedgehogs_dilemma.csv')\n",
    "# user_playlist = pd.read_csv('../Playlists/you_wanna_rock.csv')\n",
    "user_tracks = [] # Output of list of track dicts\n",
    "track_info_100 = [] # Intermediate list for storing track info\n",
    "track_ids_100 = [] # Intermediate list for storing track ids\n",
    "for index, row in user_playlist.iterrows():\n",
    "    id = row['Track URI'][14:]\n",
    "    track_ids_100.append(id)\n",
    "    track_info = {\n",
    "        '':index,\n",
    "        'artist_name': row['Artist Name(s)'],\n",
    "        'track_name': row['Track Name'],\n",
    "        'track_id': id,\n",
    "        # ... we will add more attributes later\n",
    "    }\n",
    "    track_info_100.append(track_info)\n",
    "\n",
    "    if len(track_ids_100) == 100 or index == len(user_playlist) - 1:\n",
    "        response = sp.audio_features(track_ids_100)\n",
    "        print(f\"Successful response with {len(response)} entries\")\n",
    "        # Update track info for each song\n",
    "        for response_index, audio_features in enumerate(response):\n",
    "            if audio_features:  # Check if audio_features is not None\n",
    "                for feature in features:\n",
    "                    track_info_100[response_index][feature] = audio_features[feature]\n",
    "                user_tracks.append(track_info_100[response_index])\n",
    "        # Reset intermediate variables\n",
    "        print(f\"Total songs stored so far: {len(user_tracks) = }\")\n",
    "        track_ids_100 = []\n",
    "        track_info_100 = []\n",
    "        time.sleep(2)\n",
    "user_df = pd.DataFrame(user_tracks)\n",
    "print(user_df) # The printed index should be the length of user playlist minus one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude track name, artist name, track id, index,...\n",
    "user_features = user_df[features] \n",
    "# Get centroid vector of user playlist\n",
    "centroid_vec = user_features.mean(axis=0)\n",
    "user_centroid = pd.DataFrame(centroid_vec).transpose()\n",
    "print(user_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ GET CENTROIDS OF 1K PLAYLIST DATASET ------------------------------\n",
    "slices = [\"0-999\", \"1000-1999\", \"2000-2999\", \"3000-3999\", \"4000-4999\", \"5000-5999\", \"6000-6999\", \"7000-7999\", \"8000-8999\", \"9000-9999\"]\n",
    "# ---------- YOUR FILEPATHS HERE ----------\n",
    "FILENAME = \"mpd.slice.0-999.json\"\n",
    "FOLDER = r\"../spotify_million_playlist_dataset/data\"\n",
    "PATH = FOLDER + \"/\" + FILENAME\n",
    "# ---------- YOUR FILEPATHS HERE ----------\n",
    "playlists = []\n",
    "index = 1\n",
    "for slice in slices:\n",
    "    FILENAME = \"mpd.slice.{}.json\".format(slice)\n",
    "    dataset_tracks = pd.read_csv('../mpd.slice.{}.csv'.format(slice))\n",
    "    with open(PATH, \"r\") as playlist_file:\n",
    "        batch = json.load(playlist_file)\n",
    "        print(f\"Loading complete! Beginning parsing...\")\n",
    "        # Loop through all playlists\n",
    "        for playlist_index, playlist in enumerate(batch[\"playlists\"]):\n",
    "            print(f\"\\nScanned playlist {playlist_index} ({len(playlist['tracks'])} songs)\")\n",
    "            playlist_tracks = []\n",
    "            # Loop through tracks in playlist\n",
    "            for track_index, track in enumerate(playlist[\"tracks\"]):\n",
    "                id = track[\"track_uri\"][14:]\n",
    "                # Search for playlist track in dataset\n",
    "                matches = dataset_tracks[dataset_tracks['track_id'] == id]\n",
    "                if matches.empty:\n",
    "                    continue\n",
    "                # Get one of the matches as a DataFrame (all should be the same data, just different indices)\n",
    "                match = matches.iloc[[0]]\n",
    "                track_features = match.to_dict('records')[0] # Convert DataFrame to Dictionary\n",
    "                playlist_tracks.append(track_features)\n",
    "\n",
    "            if len(playlist_tracks) > 0: # Non-empty number of tracks in playlist\n",
    "                playlists.append(pd.DataFrame(playlist_tracks))\n",
    "    print(f\"Considering {len(playlists)} out of {index*1000} playlists in {slice} json.\")\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playlists is a list holding each playlist\n",
    "# each playlist is a dataframe holding dicts (rows) of tracks\n",
    "print(len(playlists))\n",
    "for playlist in playlists:\n",
    "    #print(playlist)\n",
    "    print(playlist.columns)\n",
    "    break\n",
    "    print(\"playlist type\", type(playlist))\n",
    "    for track in playlist:\n",
    "        print(\"track type\", type(track))\n",
    "        print(track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ CALCULATE PLAYLIST CENTROIDS ------------------------------\n",
    "features = ['danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
    "centroids = []\n",
    "for index, playlist in enumerate(playlists):\n",
    "    # Exclude track name, artist name, track id, index,...\n",
    "    pl_features = playlist[features] \n",
    "    # Get centroid vector of user playlist\n",
    "    centroid_vec = pl_features.mean(axis=0)\n",
    "    pl_centroid = pd.DataFrame(centroid_vec).transpose()\n",
    "    centroids.append(pl_centroid)\n",
    "    # print(pl_centroid)\n",
    "\n",
    "# Convert centroids to a DataFrame for clustering\n",
    "centroids_df = pd.concat(centroids, ignore_index=True) # Stack dataframes on top of each other as rows\n",
    "print(centroids_df)\n",
    "# found = centroids_df.iloc[0] # Get first row centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_clusters(data, max_k=20):\n",
    "    # Drop the 'cluster' column from centroids_df to exclude it from the input\n",
    "    if 'cluster' in data.columns:\n",
    "        data = data.drop(columns=['cluster'])\n",
    "    \n",
    "    scaled_data = scaler.fit_transform(data[features])\n",
    "    inertia = []\n",
    "\n",
    "    for k in range(1, max_k + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(scaled_data)\n",
    "        inertia.append(kmeans.inertia_)\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(range(1, max_k + 1), inertia, marker='o')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.title('Elbow Method')\n",
    "    plt.show()\n",
    "\n",
    "find_optimal_clusters(centroids_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ CLUSTER PLAYLISTS ------------------------------\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Drop the 'cluster' column from centroids_df to exclude it from the input\n",
    "if 'cluster' in centroids_df.columns:\n",
    "    centroids_df = centroids_df.drop(columns=['cluster'])\n",
    "\n",
    "# Perform k-means clustering on the playlist centroids\n",
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "# Standardize Feature Columns\n",
    "scaler = StandardScaler()\n",
    "scaled_centroids_df = scaler.fit_transform(centroids_df[features])\n",
    "# KMeans Cluster\n",
    "kmeans.fit(scaled_centroids_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nClustered Playlist Centroids:\")\n",
    "# print(centroids_df.head(5))\n",
    "print(\"\\nScaled Clustered Playlist Centroids:\")\n",
    "print(scaled_centroids_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ ASSIGN USER PLAYLIST ------------------------------\n",
    "user_cluster = kmeans.predict(user_centroid)\n",
    "print(f\"Predicted cluster: {user_cluster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster labels to the centroids DataFrame\n",
    "# centroids_df['cluster'] = kmeans.labels_\n",
    "\n",
    "# print(\"\\nClustered Playlist Centroids:\")\n",
    "# print(centroids_df.head(5))\n",
    "centroids_df['cluster'] = kmeans.fit_predict(scaled_centroids_df)\n",
    "print(centroids_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ GET USER CLUSTER ------------------------------\n",
    "# Find rows in centroids_df that have the same cluster as the user\n",
    "factors = ['Unnamed: 0', 'artist_name', 'track_name', 'track_id', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature']\n",
    "\n",
    "relevant = centroids_df[centroids_df['cluster'] == float(user_cluster[0])] # DataFrame of rows with centroids and cluster\n",
    "# Get indices of rows\n",
    "indices = relevant.index\n",
    "# Loop through relevant playlists\n",
    "relevant_playlists = []\n",
    "for pl_index in indices:\n",
    "    relevant_playlists.append(playlists[pl_index]) # Append DataFrame playlist\n",
    "relevant_tracks = pd.concat(relevant_playlists, ignore_index=True)\n",
    "print(len(relevant_tracks))\n",
    "# Remove Duplicates by: Subtracting user_df from relevant_tracks based on 'id'\n",
    "relevant_tracks = pd.merge(relevant_tracks, user_df, on='track_id',how='left',suffixes=('','_a'), indicator=True).query('_merge == \"left_only\"')\n",
    "relevant_tracks = relevant_tracks[factors] # Remove duplicate columns\n",
    "relevant_features = relevant_tracks[features] # Remove track_name, artist_name, id, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = euclidean_distances(user_centroid, relevant_features).flatten()\n",
    "# Add distances to relevant_tracks DataFrame\n",
    "relevant_tracks['distance'] = distances\n",
    "\n",
    "# Sort by Euclidean distance and select top n_recs\n",
    "n_recs = 5\n",
    "recommendations = relevant_tracks.sort_values(by=['distance'], ascending=[True]).drop_duplicates(subset=['track_id']).head(n_recs)\n",
    "\n",
    "# We should always be able to find enough recs unless it's an absurdly large amount\n",
    "\n",
    "print(\"Here are some songs I recommend adding to your playlist!\")\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was our user playlist centroid?\n",
    "print(user_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing stuff?\n",
    "import matplotlib.pyplot as plt\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(centroids_df)\n",
    "\n",
    "Df = pd.DataFrame(data=principalComponents,\n",
    "                           columns=['principal component 1', 'principal component 2'])\n",
    "finalDf = pd.concat([Df, centroids_df[['cluster']]], axis=1)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(Df['principal component 1'], Df['principal component 2'], c=centroids_df['cluster'].values, cmap='viridis')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.title('PCA Visualization of Tracks')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA on the centroids\n",
    "pca = PCA(n_components=2)\n",
    "centroids_pca = pca.fit_transform(centroids_df)\n",
    "\n",
    "# Plot PCA-transformed data points\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(centroids_pca[:, 0], centroids_pca[:, 1], c=kmeans.labels_, cmap='viridis', s=100, alpha=0.8)\n",
    "\n",
    "# Plot centroids\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='x', s=200, label='Centroids')\n",
    "\n",
    "plt.title('PCA Plot with Centroids')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids_df.to_csv('centroids_with_clusters.csv', na_rep='NA', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Function to convert the Playlists (list of DFs) to a JSON serializable structure\n",
    "def playlists_to_json(playlists_list):\n",
    "    serializable_data = []\n",
    "    for index, playlist_df in enumerate(playlists_list):\n",
    "        if 'Unnamed: 0' in playlist_df:\n",
    "            playlist_df = playlist_df.drop(columns='Unnamed: 0')\n",
    "        nested_dict = playlist_df.to_dict(orient='records')\n",
    "        entry = {'Index': index, 'Tracks': nested_dict}\n",
    "        serializable_data.append(entry)\n",
    "    return serializable_data\n",
    "\n",
    "# Convert Playlists (list of DFs) to write back\n",
    "json_wb = playlists_to_json(playlists)\n",
    "with open('output.json', 'w') as json_file:\n",
    "    json.dump(json_wb, json_file, indent=4)\n",
    "\n",
    "# Print the JSON structure for verification\n",
    "print(json.dumps(json_wb, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
